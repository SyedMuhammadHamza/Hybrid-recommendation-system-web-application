{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metric-impossible",
   "metadata": {},
   "source": [
    "# Hybrid recommendation algorithm\n",
    "## Introduction:\n",
    "Over the last two decades, recommender systems have become State-of-the-Art Algorithms and can be regarded as success factors for companies such as Google, Amazon, and Netflix \n",
    "\n",
    "<blockquote>The goal of a recommender system is to generate meaningful recommendations to a collection of users for items or products that might interest them. Suggestions for books on Amazon, or movies on Netflix, are real-world examples of the operation of industry-strength recommender systems. The design of such recommendation engines depends on the domain and the particular characteristics of the data available. For example, movie watchers on Netflix frequently provide ratings on a scale of 1 (disliked) to 5 (liked)</blockquote>\n",
    "\n",
    "During my third year of bachelor's in Computer Sciences, I was introduced to the idea of recommender systems by a buddy of mine since then recommender systems been one of the most thought-provoking Machine learning algorithms for me. Today I'm going to introduce a recommendation algorithm that's a regression-based hybrid of content-based and collaborative filtering recommender systems. This Hybrid recommendation algorithm is highly inspired by the recommender systems approach of Andrew ng along with some research papers, I have attached in references\n",
    "\n",
    "The dataset used is provided by [GroupLens](https://grouplens.org/about/what-is-grouplens/) and  can be downloaded from [here](https://grouplens.org/datasets/movielens/) it contains the following files(links.csv, movies.csv, ratings.csv, and tags.csv)\n",
    "\n",
    "<blockquote>\"This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996, and September 24, 2018. This dataset was generated on September 26, 2018.\"</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-divorce",
   "metadata": {},
   "source": [
    "generally, recommender systems falls into three categories\n",
    "![title](images/categories.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-invite",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "egyptian-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-essence",
   "metadata": {},
   "source": [
    "## Accessing PostgreSQL Database Server from Python with ODBC\n",
    "To establish a connection to my PostgreSQL Database Server I'm gonna be using odbc (Open Database Connectivity) that's the standard that says if you write to through this protocol this standard API then you can work with ODBC it accomplishes DBMS independence by using an ODBC driver as a translation layer between the application and the DBMS. The application uses ODBC functions through an ODBC driver manager with which it is linked, and the driver passes the query to the DBMS. An ODBC driver can be thought of as analogous to a printer driver or other driver, providing a standard set of functions for the application to use, and implementing DBMS-specific functionality. An application that can use ODBC is referred to as \"ODBC-compliant\". Any ODBC-compliant application can access any DBMS for which a driver is installed. Drivers exist for all major DBMSs and it's a plug-and-play kind of thing so there are drivers for ODBC for databases like Oracle, PostgreSQL, MySQL, and Microsoft SQL Server but you've to manually install DBMS of your choice and configure its driver before using it in your python code here I've already done it for PostgreSQL hence, I can use my PostgreSQL DRIVER named {PostgreSQL Unicode} in my code to establish the connection to PostgreSQL Database\n",
    "\n",
    "<b> Please pay pilgrimage to PostgreSQLconnection class I have defined in PostgreSQL_Database_wrapper.py to understand the methods I'm going to use. I've provided docstrings for all methods that I'm going to use with my PostgreSQLconnection object here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "focal-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to database.\n"
     ]
    }
   ],
   "source": [
    "#importing PostgreSQLconnection class from my PostgreSQL_Database_wrapper file and creating an instance of it\n",
    "from PostgreSQL_Database_wrapper import PostgreSQLconnection\n",
    "db=PostgreSQLconnection(\"DRecommenderSystem_db\",\"postgres\",\"*******\",\"localhost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-parameter",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset that I'm going to use for training my hybrid recommender algorithm is going to be the join of the Ratings and Movies tables created during EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Heat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating                        title\n",
       "0       1        1     4.0             Toy Story (1995)\n",
       "1       1        3     4.0      Grumpier Old Men (1995)\n",
       "2       1        6     4.0                  Heat (1995)\n",
       "3       1       47     5.0  Seven (a.k.a. Se7en) (1995)\n",
       "4       1       50     5.0   Usual Suspects, The (1995)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=  '''      \n",
    "        SELECT Ratings.userId,Ratings.movieId,Ratings.rating,Movies.title\n",
    "        FROM Ratings\n",
    "        LEFT JOIN Movies\n",
    "        ON Ratings.movieId = Movies.movieId;\n",
    "        '''\n",
    "data=db.run_query(query)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-milan",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Before introducing the hybrid recommender algorithm it's better to understand what kind of data recommender system algorithms works with. The data for Recommender system algorithms is almost always identical to the table above in place of movieId  it can be bookId, productId et cetera. The feature engineering step here involves the transformation of data into a user-item interaction matrix\n",
    "\n",
    "<blockquote>User-item interaction matrices generally lists users and items in rows and columns, respectively. Then, the interaction records between them are represented as corresponding elements in the matrix</blockquote>\n",
    "\n",
    "\n",
    "There are only two objectives of feature engineering to get data ready for training for this problem\n",
    "## 1)Transform the data into matrix Y (user-item interaction matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-greece",
   "metadata": {},
   "source": [
    "![title](images/Ymatrix.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stock-antenna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userid   1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
       "movieid                                                    ...                  \n",
       "1        4.0  NaN  NaN  NaN  4.0  NaN  4.5  NaN  NaN  NaN  ...  4.0  NaN  4.0   \n",
       "2        NaN  NaN  NaN  NaN  NaN  4.0  NaN  4.0  NaN  NaN  ...  NaN  4.0  NaN   \n",
       "3        4.0  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "4        NaN  NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "5        NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "userid   604  605  606  607  608  609  610  \n",
       "movieid                                     \n",
       "1        3.0  4.0  2.5  4.0  2.5  3.0  5.0  \n",
       "2        5.0  3.5  NaN  NaN  2.0  NaN  NaN  \n",
       "3        NaN  NaN  NaN  NaN  2.0  NaN  NaN  \n",
       "4        NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "5        3.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 610 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MatrixData=data.drop(['title'], axis=1)\n",
    "MovieUserMatrix = MatrixData.pivot_table(index='movieid',columns='userid',values='rating')\n",
    "MovieUserMatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wanted-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193581</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193583</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193585</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193587</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193609</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9724 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userid   1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
       "movieid                                                    ...                  \n",
       "1        4.0 -1.0 -1.0 -1.0  4.0 -1.0  4.5 -1.0 -1.0 -1.0  ...  4.0 -1.0  4.0   \n",
       "2       -1.0 -1.0 -1.0 -1.0 -1.0  4.0 -1.0  4.0 -1.0 -1.0  ... -1.0  4.0 -1.0   \n",
       "3        4.0 -1.0 -1.0 -1.0 -1.0  5.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "4       -1.0 -1.0 -1.0 -1.0 -1.0  3.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "5       -1.0 -1.0 -1.0 -1.0 -1.0  5.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "193581  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "193583  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "193585  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "193587  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "193609  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "\n",
       "userid   604  605  606  607  608  609  610  \n",
       "movieid                                     \n",
       "1        3.0  4.0  2.5  4.0  2.5  3.0  5.0  \n",
       "2        5.0  3.5 -1.0 -1.0  2.0 -1.0 -1.0  \n",
       "3       -1.0 -1.0 -1.0 -1.0  2.0 -1.0 -1.0  \n",
       "4       -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "5        3.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "...      ...  ...  ...  ...  ...  ...  ...  \n",
       "193581  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "193583  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "193585  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "193587  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "193609  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "\n",
       "[9724 rows x 610 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MovieUserMatrix_Y=MovieUserMatrix.fillna(-1)\n",
    "MovieUserMatrix_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-karen",
   "metadata": {},
   "source": [
    "Transformation of data into matrix Y (user-item interaction matrix) (above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-latter",
   "metadata": {},
   "source": [
    "## 2)Transform the data into matrix R (binary-valued indicator matrix)\n",
    "![title](images/Rmatrix.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "going-chess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193581</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193583</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193585</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193587</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193609</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9724 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userid   1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
       "movieid                                                    ...                  \n",
       "1        1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  ...  1.0  0.0  1.0   \n",
       "2        0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
       "3        1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4        0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5        0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "193581   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "193583   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "193585   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "193587   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "193609   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "userid   604  605  606  607  608  609  610  \n",
       "movieid                                     \n",
       "1        1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2        1.0  1.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5        1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...      ...  ...  ...  ...  ...  ...  ...  \n",
       "193581   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "193583   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "193585   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "193587   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "193609   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[9724 rows x 610 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MovieUserMatrix_R=MovieUserMatrix.copy()\n",
    "MovieUserMatrix_R=MovieUserMatrix_R.where(~MovieUserMatrix_R.notna(), 1)\n",
    "MovieUserMatrix_R=MovieUserMatrix_R.fillna(0)\n",
    "MovieUserMatrix_R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-bargain",
   "metadata": {},
   "source": [
    "Transformation of the data into matrix R (binary-valued indicator matrix) above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infinite-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "MovieUserMatrix_Y.shape==MovieUserMatrix_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "paperback-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting values out of pandas dataframe into numpy-array because my alogorithm accept numpy-array as parameter\n",
    "Y=MovieUserMatrix_Y.values\n",
    "R=MovieUserMatrix_R.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-thriller",
   "metadata": {},
   "source": [
    "# Hybrid recommendation approach "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-consultation",
   "metadata": {},
   "source": [
    "The hybrid recommendation system that I'm going to implement consists of the following sequence of steps\n",
    "1. <b>Collaborative filtering</b>:(Used to learn Features for movies)\n",
    "2. <b>Content-based filtering</b>:(Used to learn Parameters unique to web-application user)\n",
    "3. <b>Prediction</b>: (uses both the Features for movies learned using collaborative filtering and the Parameters unique to web-application user learned using content-based filtering to recommend top-N recommendation)\n",
    "![title](images/Hybrid.jpeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-hierarchy",
   "metadata": {},
   "source": [
    "# 1. Collaborative filtering\n",
    "The main objective of collaborative filtering at this step is to learn features for different movies. The implementation of Collaborative filtering here performs \"Feature learning\" Using a variation of multivariate regression with gradient descent as an optimization algorithm, it takes as input user-item interaction matrix and simultaneously learns both the parameters for different users and features for different movies I'm only going to use Features for different movie in the next step but this technique of using both the parameters for users and feature for movies to learn both simultaneously works beautifully for a problem like recommender systems because this approach unlike content-based filtering doesn't require features for different movies to learn parameters for users or parameters for users to learn features for different movies all you need is a user-item interaction matrix and this algorithm will learn a reasonably good set of both the parameters for users and features for movies because it's a modification of multivariate regression whose optimization objective is a concave cost function that always converges towards global minima regardless of your initial values for both the parameters of users and features for different movies. Once features for movies have been learned by collaborative filtering I'm going to save them in python's [.PKL] file that serializes objects to files on disk and deserialized back into the program at runtime when needed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-retail",
   "metadata": {},
   "source": [
    "## Notations\n",
    "* <B>x(i)</B> is a feature vector for movie(i)\n",
    "* <B>θ(j)</B> is a parameter vector for user(j)\n",
    "* The <B>matrix Y</B> (user-item interaction matrix) stores the ratings (from 1 to 5) for all movies(i) by all users(j) where <B>y(i;j)</B> represet the rating for movie(i) by user (j)\n",
    "* The <B>matrix R</B> is a binary-valued indicator matrix, where r(i; j) = 1 if user j gave a rating to movie i, and r(i; j) = 0 otherwise.\n",
    "* <b>nu</b> = total number of users\n",
    "* <b>nm</b> = total number of movies.\n",
    "For this project, I'm using n = 100, and therefore, x(i) ∈ R^100 and θ(j) ∈  R^100.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-hanging",
   "metadata": {},
   "source": [
    "##  Collaborative filtering Cost function\n",
    "The cost function for this Regression-based collaborative filtering algorithm is going to be of the following form:\n",
    "![title](images/costfunc.jpg)\n",
    "\n",
    "\n",
    "## Collaborative filtering Regularized cost function\n",
    "The Regularized cost function for this Regression-based collaborative filtering algorithm is going to be of the following form:\n",
    "![title](images/costfuncRegularized.jpg)\n",
    "\n",
    "## Gradient for Collaborative filtering Cost function\n",
    "The gradient for Collaborative filtering Cost function is as follows:\n",
    "![title](images/costfuncGradient.jpg)\n",
    "\n",
    "## Gradient for Collaborative filtering Regularized Cost function\n",
    "Gradient for Collaborative filtering Regularized Cost function is as follows:\n",
    "![title](images/costfuncGradientRegularized.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "separated-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of Collaborative filtering Cost function and gradient, regularized and non regularized\n",
    "def  cofiCostFunc(params, Y, R, num_users, num_movies, num_features, Lambda):\n",
    "    \"\"\"\n",
    "            calculates Collaborative filtering Cost function and gradient both regularized and non regularized\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            params: numpy array-like\n",
    "                    initial values for users parameter vectors and movies feature vectors\n",
    "            \n",
    "            Y: numpy array-like\n",
    "                    user-item interaction matrix\n",
    "            R: numpy arra-like\n",
    "                    Its a binary-valued indicator matrix for user-item interaction matrix\n",
    "            num_users: int-like\n",
    "                    total number of users\n",
    "            num_movies: int-like\n",
    "                    total number of movies\n",
    "            Lambda: Float-like\n",
    "                    Regularization parameter\n",
    "                    \n",
    "            Returns\n",
    "            -------\n",
    "            J:Float-like\n",
    "                    Cost\n",
    "            grad:Float-like\n",
    "                    Gradient\n",
    "            reg_J:Float-like\n",
    "                    Regularized Cost\n",
    "            reg_grad:Float-like\n",
    "                    Regularized gradient\n",
    "    \"\"\"\n",
    "    # Unfold the params\n",
    "    X = params[:num_movies*num_features].reshape(num_movies,num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users,num_features)\n",
    "    \n",
    "    predictions =  np.dot(X,Theta.T)\n",
    "    err = (predictions - Y)\n",
    "    J = 1/2 * np.sum((err**2) * R)# multiplying by R will consider only those values for which value of (i,j)=r(i,j)=1\n",
    "    \n",
    "    #compute regularized cost function\n",
    "    reg_X =  Lambda/2 * np.sum(Theta**2)\n",
    "    reg_Theta = Lambda/2 *np.sum(X**2)\n",
    "    reg_J = J + reg_X + reg_Theta\n",
    "    \n",
    "    # Compute gradient\n",
    "    X_grad = np.dot(err*R,Theta)\n",
    "    Theta_grad = np.dot((err*R).T,X)\n",
    "    grad = np.append(X_grad.flatten(),Theta_grad.flatten()) #flattening calculated gradients of 4*3 dim into 12 real number one dim of vector for optimization algo since optimization algorithms deals with vectos not matrix \n",
    "    \n",
    "    # Compute regularized gradient\n",
    "    reg_X_grad = X_grad + Lambda*X\n",
    "    reg_Theta_grad = Theta_grad + Lambda*Theta\n",
    "    reg_grad = np.append(reg_X_grad.flatten(),reg_Theta_grad.flatten())\n",
    "    #, reg_J, reg_grad\n",
    "    \n",
    "    return J, grad, reg_J, reg_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-selection",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "Numerical optimization algorithm to minimize the Collaborative filtering Cost function By noting α ∈ R the learning rate, the update rule for gradient descent\n",
    "is expressed with the learning rate and the cost function J as follows:\n",
    "![title](images/GD.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "false-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient descent implementation\n",
    "def gradientDescent(initial_parameters,Y,R,num_users,num_movies,num_features,alpha,num_iters,Lambda):\n",
    "    \"\"\"\n",
    "            Optimize X and Theta\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            initial_parameters: numpy array-like\n",
    "                    initial values for users parameter vectors and movies feature vectors\n",
    "            \n",
    "            Y: numpy array-like\n",
    "                    user-item interaction matrix\n",
    "            R: numpy arra-like\n",
    "                    Its a binary-valued indicator matrix for user-item interaction matrix\n",
    "            num_users: int-like\n",
    "                    total number of users\n",
    "            num_movies: int-like\n",
    "                    total number of movies\n",
    "            alpha: Float-lik\n",
    "                    learning rate\n",
    "            num_iters: integer-like\n",
    "                    number of iterations of optimization algorithm\n",
    "            Lambda: Float-like\n",
    "                    Regularization parameter\n",
    "                    \n",
    "            Returns\n",
    "            -------\n",
    "            paramsFinal: numpy-array-like\n",
    "                    Learned user parameters and feature vectors for movies\n",
    "            J_history: numpy-array-like\n",
    "                     History of decrease in cost as gradeint descent moves towords global minima\n",
    "    \"\"\"\n",
    "    # unfold the parameters\n",
    "    X = initial_parameters[:num_movies*num_features].reshape(num_movies,num_features)\n",
    "    Theta = initial_parameters[num_movies*num_features:].reshape(num_users,num_features)\n",
    "    \n",
    "    J_history =[]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        params = np.append(X.flatten(),Theta.flatten())\n",
    "        cost, grad = cofiCostFunc(params, Y, R, num_users, num_movies, num_features, Lambda)[2:]\n",
    "        \n",
    "        # unfold grad\n",
    "        X_grad = grad[:num_movies*num_features].reshape(num_movies,num_features)\n",
    "        Theta_grad = grad[num_movies*num_features:].reshape(num_users,num_features)\n",
    "        X = X - (alpha * X_grad)\n",
    "        Theta = Theta - (alpha * Theta_grad)\n",
    "        J_history.append(cost)\n",
    "    \n",
    "    paramsFinal = np.append(X.flatten(),Theta.flatten())\n",
    "    return paramsFinal , J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "speaking-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y, R):\n",
    "    \"\"\"\n",
    "    normalized Y so that each movie has a rating of 0 on average, and returns the mean rating in Ymean.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Y: numpy array-like\n",
    "                    user-item interaction matrix\n",
    "    R: numpy arra-like\n",
    "                    Its a binary-valued indicator matrix for user-item interaction matrix\n",
    "    Ynorm:numpy array-like\n",
    "                    Normalize Y\n",
    "    Ymean:numpy array-like\n",
    "                    Mean of all movies\n",
    "    \"\"\"\n",
    "    \n",
    "    m,n = Y.shape[0], Y.shape[1]\n",
    "    Ymean = np.zeros((m,1))\n",
    "    Ynorm = np.zeros((m,n))\n",
    "    \n",
    "    for i in range(m):\n",
    "        Ymean[i] = np.sum(Y[i,:])/np.count_nonzero(R[i,:])\n",
    "        Ynorm[i,R[i,:]==1] = Y[i,R[i,:]==1] - Ymean[i]\n",
    "    return Ynorm, Ymean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-advocate",
   "metadata": {},
   "source": [
    "# 2. Content-based filtering\n",
    "The content-based filtering here again is going to be an extension of multivariate regression but unlike collaborative filtering here I'm going to use the features for movies learned using collaborative filtering now to learn online web-application user parameter using content-based filtering thats unique to the user based on his/her web application movie ratings.This content-based filtering algorithm will run and learn online the parameters unique to each web-application user  but this algorithm by no means a type of Online learning algorithm because that definition strictly includes the ability of algorithm to use sequential data coming as input online and use it to update the best predictor for future data at each step\n",
    "\n",
    "## Notations\n",
    "* <B>x(i)</B> is a feature vector for movie(i)\n",
    "* <B>θ</B> is a parameter vector for web-applicaiton user\n",
    "* <b>y(i)</b> i the rating for movie i by web-applicaiton user\n",
    "* r(i) = 1 if web-applicaiton user gave a rating to movie i, and r(i) = 0 otherwise.\n",
    "\n",
    ".\n",
    "I'm using n = 100, and therefore, x(i) ∈ R^100 and θ ∈  R^100.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-enlargement",
   "metadata": {},
   "source": [
    "## Content-based filtering Cost function\n",
    "![title](images/CBcost.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "widespread-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    \"\"\"\n",
    "            calculates cost for given value of θ \n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            X: numpy-array-like\n",
    "               matrix of features for all movies\n",
    "               \n",
    "            y: numpy-array-like\n",
    "               binary vector of web-application user movie ratings (y ∈ R^9742) where 9742 is the number of movies rated by web-app user\n",
    "                    \n",
    "            theta:numpy-array-like\n",
    "               value of θ for web application user\n",
    "               \n",
    "            Returns\n",
    "            -------\n",
    "            j: float-like\n",
    "               cost\n",
    "    \"\"\"\n",
    "    m=y.size\n",
    "    s=np.dot(X,theta)-y\n",
    "    j=(1/(2*m))*(np.dot(np.transpose(s),s))\n",
    "    return j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-spice",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "Numerical optimization algorithm to minimize the Content-based filtering  Cost function By noting α ∈ R the learning rate, the update rule for gradient descent is expressed with the learning rate and the cost function J as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-counter",
   "metadata": {},
   "source": [
    "![title](images/CF.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "removable-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBgradientDescent(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn `theta`. Updates theta by taking `num_iters`\n",
    "    gradient steps with learning rate `alpha`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        matrix of features for all movies\n",
    "    \n",
    "    y : array_like\n",
    "        binary vector of ∈ R^9742 movies where 9742 is the number of movies\n",
    "    \n",
    "    theta : array_like\n",
    "        Initial values for the web-applicaiton user parameters. \n",
    "    \n",
    "    alpha : float\n",
    "        The learning rate.\n",
    "    \n",
    "    num_iters : int\n",
    "        The number of iterations for gradient descent. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        The learned parameters. \n",
    "    \"\"\"\n",
    "    m = float(y.shape[0])\n",
    "    theta = theta.copy()\n",
    "    for i in range(num_iters):\n",
    "        theta=(theta)-(alpha/m)*(np.dot(np.transpose((np.dot(X,theta)-y)),X))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-nancy",
   "metadata": {},
   "source": [
    "# 3. Prediction\n",
    "Prediction (uses both the Features for movies learned using collaborative filtering and the Parameters unique to user learned using content-based filtering to recommend top-N recommendation)\n",
    "The prediction uses both the vectors for movies learned using collaborative filtering and the parameter unique to user learned using content-based filtering to recommend top-N recommendation\n",
    "\n",
    "The  prediction logic for my web application user is pretty straightforward I'm going to predict the score for all 9742 movies, where each prediction is a linear combination of Movie feature vector (x) learned using Collaborative filtering  and Feature vector for web-application user θ  learned using content-based filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-frank",
   "metadata": {},
   "source": [
    "![title](images/predi.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simplified-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X,my_ratings,moviesdataset):\n",
    "    \"\"\"\n",
    "    Performs prediction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        matrix of features for all movies\n",
    "    \n",
    "    my_ratings : numpy-array-like\n",
    "        Binary vector of web-application user movie ratings (y ∈ R^9742) where 9742 is the number of movies rated by web-app user\n",
    "                    \n",
    "    moviesdataset : pandas dataframe-like\n",
    "        Dataframe contains movieid and title for all 9742 movies\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sorted_data : array_like\n",
    "        top-N recommendation\n",
    "    \n",
    "    \"\"\"\n",
    "    out_arr = my_ratings[np.nonzero(my_ratings)]\n",
    "    out_arr=out_arr.reshape(-1,1)\n",
    "    idx = np.where(my_ratings)[0]\n",
    "    X_1=[X[x] for x in idx]\n",
    "    X_1=np.array(X_1)\n",
    "    y=out_arr\n",
    "    y=np.reshape(y, -1)\n",
    "    theta =CBgradientDescent(X_1,y,np.zeros((100)),0.001,4000)\n",
    "    #mean=np.reshape(Ymean, -1)\n",
    "    p = X @ theta.T\n",
    "    #p=p+mean\n",
    "    p=np.reshape(p, -1)\n",
    "    predictedData=moviesdataset.copy()\n",
    "    predictedData['Pridiction']=p\n",
    "    sorted_data=predictedData.sort_values(by=['Pridiction'],ascending=False)\n",
    "    return sorted_data[:40]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-psychology",
   "metadata": {},
   "source": [
    "# Training and Evaluation of Recommendation Model\n",
    "Unlike classification and regression problems, there is no hard-and-fast rule when it comes to the evaluation of recommender systems At the end of the day, system designer employing a recommendation system must choose between a set of candidate approaches \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-stock",
   "metadata": {},
   "source": [
    "## Train-Test split\n",
    "For Train-Test split, there are again numerous techniques available [this](https://arxiv.org/pdf/2007.13237.pdf) paper is a great read on this subject for this project I will split my data into training and test sets by removing 10 ratings per user from the training set and placing them in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "above-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(Yratings,Rratings):\n",
    "    \"\"\"\n",
    "    train and test split\n",
    "    Parameters\n",
    "    ----------\n",
    "    Yratings: numpy array-like\n",
    "                    user-item interaction matrix\n",
    "    Rratings: numpy arra-like\n",
    "                    Its a binary-valued indicator matrix for user-item interaction matrix\n",
    "                    \n",
    "    Returns\n",
    "    -------\n",
    "    Ytrain: numpy array-like\n",
    "                   train user-item interaction matrix\n",
    "    Ytest:  numpy array-like\n",
    "                   test user-item interaction matrix\n",
    "    Rtrain: numpy array-like\n",
    "                   train its a binary-valued indicator matrix for user-item interaction matrix\n",
    "    Rtest:  numpy array-like\n",
    "                   test its a binary-valued indicator matrix for user-item interaction matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    Ytest = np.zeros(Yratings.shape)\n",
    "    Ytrain = Yratings.copy()\n",
    "    Rtest = np.zeros(Rratings.shape)\n",
    "    Rtrain = Rratings.copy()\n",
    "    \n",
    "    for user in range(Yratings.shape[0]):\n",
    "        try:\n",
    "            test_ratings = np.random.choice(Yratings[user, :].nonzero()[0], \n",
    "                                            size=10, \n",
    "                                            replace=False)\n",
    "            Ytrain[user, test_ratings] = 0.\n",
    "            Ytest[user, test_ratings] = Yratings[user, test_ratings]\n",
    "            \n",
    "            Rtrain[user, test_ratings] = 0.\n",
    "            Rtest[user, test_ratings] = Rratings[user, test_ratings]\n",
    "        except ValueError:\n",
    "            test_ratings = np.random.choice(Yratings[user, :].nonzero()[0], \n",
    "                                            size=10, \n",
    "                                            replace=True)\n",
    "            Ytrain[user, test_ratings] = 0.\n",
    "            Ytest[user, test_ratings] = Yratings[user, test_ratings]\n",
    "            \n",
    "            Rtrain[user, test_ratings] = 0.\n",
    "            Rtest[user, test_ratings] = Rratings[user, test_ratings]\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((Ytrain * Ytest) == 0))\n",
    "    assert(np.all((Rtrain * Rtest) == 0))\n",
    "    return Ytrain, Ytest, Rtrain, Rtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "driven-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cost function using Gradient Descent')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train-Test split\n",
    "Ytrain, Ytest, Rtrain, Rtest = train_test_split(Y,R)\n",
    "num_users = Ytrain.shape[1]\n",
    "num_movies = Ytrain.shape[0]\n",
    "num_features = 100\n",
    "\n",
    "# Set initial Parameters (Theta,X)\n",
    "X = np.random.randn(num_movies, num_features)\n",
    "Theta = np.random.randn(num_users, num_features)\n",
    "initial_parameters = np.append(X.flatten(),Theta.flatten())\n",
    "Lambda = 10\n",
    "\n",
    "# learns Features for movies and parameters for all users using Collaborative filtering\n",
    "paramsFinal, J_history = gradientDescent(initial_parameters,Ytrain,Rtrain,num_users,num_movies,num_features,0.001,1000,Lambda)\n",
    "\n",
    "plt.plot(J_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"$J(\\Theta)$\")\n",
    "plt.title(\"Cost function using Gradient Descent\")\n",
    "X = paramsFinal[:num_movies*num_features].reshape(num_movies,num_features)\n",
    "Theta = paramsFinal[num_movies*num_features:].reshape(num_users,num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-small",
   "metadata": {},
   "source": [
    "The above curve informs that the Collaborative filtering is indeed working and with each iteration of Gradient descent the cost of my cost function is going down and plateaued out around 200 and from there onwards the change is constant "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-trinidad",
   "metadata": {},
   "source": [
    "## Learning Curve Analysis\n",
    "For the evaluation of recommender systems, I'm going to use the MSE metric but just calculating MSE  alone for both train and test set means nothing I need to perform a learning curve analysis to better understand the quality of my model performance to that end I will train my model on different sizes of train set and evaluate both the training and test set MSE score for a given size of train and test set and let the learning curves guide me to the further improvement of my model based on the result of the learning curve my model can be suffering from bias problem, variance problem or if I'm lucky enough then I will in goldilock zone which is the ideal situation.\n",
    "\n",
    "\n",
    "<b>NOTE</b>: the dataset used in this notebook is the smallest available on  MovieLens of only 1 MB this one is only intended for educational purposes hence the learning curves are not going to be ideal by any means but I've trained the final model that I've deployed on 265 MB dataset from movieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceramic-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "wanted-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(Ytrain,Rtrain,Ytest,Rtest):\n",
    "    \"\"\"\n",
    "    compute data for learning Curve\n",
    "                    \n",
    "    Parameters\n",
    "    -------\n",
    "    Ytrain: numpy array-like\n",
    "                   train user-item interaction matrix\n",
    "    Ytest:  numpy array-like\n",
    "                   test user-item interaction matrix\n",
    "    Rtrain: numpy array-like\n",
    "                   train its a binary-valued indicator matrix for user-item interaction matrix\n",
    "    Rtest:  numpy array-like\n",
    "                   test its a binary-valued indicator matrix for user-item interaction matrix\n",
    "                   \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    train_size_hist: numpy array-like\n",
    "                   different training set sizes used\n",
    "    train_score_hist: numpy array-like\n",
    "                   scores relative to training size\n",
    "    test_size_hist: numpy array-like\n",
    "                   different test set sizes used\n",
    "    test_score_hist: numpy array-like\n",
    "                   scores relative to training size\n",
    "    \n",
    "    \"\"\"\n",
    "    Y=Ytrain\n",
    "    R=Rtrain\n",
    "    test_Y=Ytest\n",
    "    test_R=Rtest\n",
    "    train_size_hist=[]\n",
    "    train_score_hist=[]\n",
    "    test_size_hist=[]\n",
    "    test_score_hist=[]\n",
    "    size_list=[1,100,800,1000,1500,2000,2500,3000,3300,3800,4800,5900,6500,7000,7600,8300,9724]\n",
    "    for size in size_list:\n",
    "        Ytrain=Y[:size]\n",
    "        Rtrain=R[:size]\n",
    "        Ytest=test_Y[:size]\n",
    "        Rtest=test_R[:size]\n",
    "        num_users = Ytrain.shape[1]\n",
    "        num_movies = Ytrain.shape[0]\n",
    "        num_features = 100\n",
    "\n",
    "        # Set initial Parameters (Theta,X)\n",
    "        X = np.random.randn(num_movies, num_features)\n",
    "        Theta = np.random.randn(num_users, num_features)\n",
    "        initial_parameters = np.append(X.flatten(),Theta.flatten())\n",
    "        Lambda = 10\n",
    "\n",
    "        # Optimize parameters using Gradient Descent\n",
    "        paramsFinal, J_history = gradientDescent(initial_parameters,Ytrain,Rtrain,num_users,num_movies,num_features,0.001,1000,Lambda)\n",
    "        X = paramsFinal[:num_movies*num_features].reshape(num_movies,num_features)\n",
    "        Theta = paramsFinal[num_movies*num_features:].reshape(num_users,num_features)\n",
    "        pred = X @ Theta.T\n",
    "        pred=pred*Rtrain\n",
    "        actual=Ytrain\n",
    "        train_size_hist.append(size)\n",
    "        train_score_hist.append(get_mse(pred, actual))\n",
    "        pred = X @ Theta.T\n",
    "        pred=pred*Rtest\n",
    "        actual=Ytest\n",
    "        test_size_hist.append(size)\n",
    "        test_score_hist.append(get_mse(pred, actual))\n",
    "    return train_size_hist,train_score_hist,test_size_hist,test_score_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dressed-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_hist,train_score_hist,test_size_hist,test_score_hist=learningCurve(Ytrain,Rtrain,Ytest,Rtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "signal-mathematics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97, 1.05)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(train_size_hist, train_score_hist, label = 'Training error')\n",
    "plt.plot(train_size_hist, test_score_hist, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.yticks(np.arange(0,2, 0.25))\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a Collaborative Filtering', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim(0.97,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-prisoner",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "As I mentioned earlier the dataset used in this notebook is the smallest available on  MovieLens of only 1 MB this one is only intended for educational purposes hence these learning curves are not ideal by any means more specifically the gap between the two learning curves suggests a substantial increase in variance. The low training MSEs corroborate this diagnosis of high variance. The large gap and the low training error also indicate an overfitting problem. Overfitting happens when the model performs well on the training set, but far poorer on the test (or validation) set. One more important observation we can make here is that adding new training instances is very likely to lead to a better model that's exactly what I did and trained my model for the 265 MB dataset from movieLens. another thing to be noted here is the sizes used for learning curves are randomly cherry-picked by me if the learning curve analysis is performed for every possible size the learning curves will be much smoother\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "proved-forth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>grumpier old men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>waiting to exhale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>father of the bride part ii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid                         title\n",
       "0        1                    toy story \n",
       "1        2                      jumanji \n",
       "2        3             grumpier old men \n",
       "3        4            waiting to exhale \n",
       "4        5  father of the bride part ii "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning and transforming moviesDataset to use it on web-application \n",
    "moviesdataset=data.drop(['userid','rating'],axis=1)\n",
    "moviesdataset=moviesdataset.drop_duplicates()\n",
    "moviesdataset=moviesdataset.sort_values(\"movieid\")\n",
    "moviesdataset=moviesdataset.reset_index(drop=True)\n",
    "moviesdataset[\"title\"] = moviesdataset[\"title\"].str.lower() \n",
    "moviesdataset[\"title\"] = moviesdataset[\"title\"].str.replace(r\"\\(.*\\)\",\"\")\n",
    "moviesdataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-force",
   "metadata": {},
   "source": [
    "## Testing \n",
    "Now at this point, I'm all set to start the <b> flask web application</b>  development but before moving onwards I'm just going to test if everything working with my content-based filtering algorithm for that end I'm going to test my content-based filtering algorithm out\n",
    "I've already learned the feature vectors for all movie using a collaborative filtering algorithm now as a new user on web application rates a handful of movies my content-based filtering algorithm will use learned the feature vectors for all movies using collaborative filtering algorithm and ratings by the web application user to learn parameter unique to this web-application user and then perform the linear combination prediction logic to recommend top-N-movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "historical-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings:\n",
      "\n",
      "Rated 4 for Movie\n",
      "toy story \n",
      "Rated 3 for Movie\n",
      "sabrina \n",
      "Rated 5 for Movie\n",
      "dracula: dead and loving it \n",
      "Rated 4 for Movie\n",
      "indian in the cupboard, the \n",
      "Rated 5 for Movie\n",
      "fair game \n",
      "Rated 3 for Movie\n",
      "misérables, les \n",
      "Rated 5 for Movie\n",
      "screamers \n",
      "Rated 4 for Movie\n",
      "vampire in brooklyn \n",
      "Rated 2 for Movie\n",
      "braveheart \n",
      "Rated 5 for Movie\n",
      "little women \n",
      "Rated 5 for Movie\n",
      "above the rim \n"
     ]
    }
   ],
   "source": [
    "# Initialize my ratings\n",
    "my_ratings = np.zeros((9724,1))\n",
    "\n",
    "# test rating by web-applicaiton user\n",
    "my_ratings[0] = 4 \n",
    "my_ratings[97] = 2\n",
    "my_ratings[6] = 3\n",
    "my_ratings[11]= 5\n",
    "my_ratings[53] = 4\n",
    "my_ratings[63]= 5\n",
    "my_ratings[65]= 3\n",
    "my_ratings[68] = 5\n",
    "my_ratings[82]= 4\n",
    "my_ratings[225] = 5\n",
    "my_ratings[354]= 5\n",
    "\n",
    "print(\"New user ratings:\\n\")\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i]>0:\n",
    "        print(\"Rated\",int(my_ratings[i]),\"for Movie\")\n",
    "        print((moviesdataset.iloc[i]).title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "according-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>title</th>\n",
       "      <th>Pridiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>27667</td>\n",
       "      <td>ju-on: the curse</td>\n",
       "      <td>5.006813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>76</td>\n",
       "      <td>screamers</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>409</td>\n",
       "      <td>above the rim</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>261</td>\n",
       "      <td>little women</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>71</td>\n",
       "      <td>fair game</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>dracula: dead and loving it</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9474</th>\n",
       "      <td>170401</td>\n",
       "      <td>table 19</td>\n",
       "      <td>4.796291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>8954</td>\n",
       "      <td>lightning in a bottle</td>\n",
       "      <td>4.791735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>130052</td>\n",
       "      <td>clown</td>\n",
       "      <td>4.534622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>4263</td>\n",
       "      <td>days of wine and roses</td>\n",
       "      <td>4.482884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>2392</td>\n",
       "      <td>jack frost</td>\n",
       "      <td>4.463186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>3894</td>\n",
       "      <td>solas</td>\n",
       "      <td>4.343312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>7118</td>\n",
       "      <td>wings of honneamise</td>\n",
       "      <td>4.278852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>3041</td>\n",
       "      <td>meatballs part ii</td>\n",
       "      <td>4.237588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>1127</td>\n",
       "      <td>abyss, the</td>\n",
       "      <td>4.231771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>6329</td>\n",
       "      <td>manic</td>\n",
       "      <td>4.230143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>39381</td>\n",
       "      <td>proposition, the</td>\n",
       "      <td>4.153444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>4969</td>\n",
       "      <td>and then there were none</td>\n",
       "      <td>4.125573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>31522</td>\n",
       "      <td>marriage of maria braun, the</td>\n",
       "      <td>4.110633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>92422</td>\n",
       "      <td>woman in black, the</td>\n",
       "      <td>4.090681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6762</th>\n",
       "      <td>60289</td>\n",
       "      <td>kit kittredge: an american girl</td>\n",
       "      <td>4.076885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022</th>\n",
       "      <td>141668</td>\n",
       "      <td>war room</td>\n",
       "      <td>4.060757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>159161</td>\n",
       "      <td>ali wong: baby cobra</td>\n",
       "      <td>4.014585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7115</th>\n",
       "      <td>71254</td>\n",
       "      <td>gamer</td>\n",
       "      <td>4.007557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>toy story</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>60</td>\n",
       "      <td>indian in the cupboard, the</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>93</td>\n",
       "      <td>vampire in brooklyn</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>579</td>\n",
       "      <td>escort, the</td>\n",
       "      <td>3.999252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>39292</td>\n",
       "      <td>good night, and good luck.</td>\n",
       "      <td>3.954468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8468</th>\n",
       "      <td>113278</td>\n",
       "      <td>batman: assault on arkham</td>\n",
       "      <td>3.941009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8746</th>\n",
       "      <td>128594</td>\n",
       "      <td>boy meets girl</td>\n",
       "      <td>3.929628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>5442</td>\n",
       "      <td>v. i. warshawski</td>\n",
       "      <td>3.927033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>3634</td>\n",
       "      <td>seven days in may</td>\n",
       "      <td>3.922425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9220</th>\n",
       "      <td>153386</td>\n",
       "      <td>long live ghosts!</td>\n",
       "      <td>3.916527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>6588</td>\n",
       "      <td>and now... ladies and gentlemen...</td>\n",
       "      <td>3.908459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>132888</td>\n",
       "      <td>comedy central roast of james franco</td>\n",
       "      <td>3.882490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>7820</td>\n",
       "      <td>virgin spring, the</td>\n",
       "      <td>3.880780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>26791</td>\n",
       "      <td>shining through</td>\n",
       "      <td>3.861796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1914</td>\n",
       "      <td>smoke signals</td>\n",
       "      <td>3.839327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>8934</td>\n",
       "      <td>bebe's kids</td>\n",
       "      <td>3.834800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieid                                  title  Pridiction\n",
       "5658    27667                      ju-on: the curse     5.006813\n",
       "68         76                             screamers     5.000000\n",
       "354       409                         above the rim     5.000000\n",
       "225       261                          little women     5.000000\n",
       "63         71                             fair game     5.000000\n",
       "11         12           dracula: dead and loving it     5.000000\n",
       "9474   170401                              table 19     4.796291\n",
       "5358     8954                 lightning in a bottle     4.791735\n",
       "8777   130052                                 clown     4.534622\n",
       "3163     4263                days of wine and roses     4.482884\n",
       "1792     2392                            jack frost     4.463186\n",
       "2900     3894                                 solas     4.343312\n",
       "4772     7118                   wings of honneamise     4.278852\n",
       "2292     3041                     meatballs part ii     4.237588\n",
       "855      1127                            abyss, the     4.231771\n",
       "4324     6329                                 manic     4.230143\n",
       "6016    39381                      proposition, the     4.153444\n",
       "3614     4969              and then there were none     4.125573\n",
       "5771    31522          marriage of maria braun, the     4.110633\n",
       "7790    92422                   woman in black, the     4.090681\n",
       "6762    60289       kit kittredge: an american girl     4.076885\n",
       "9022   141668                              war room     4.060757\n",
       "9289   159161                  ali wong: baby cobra     4.014585\n",
       "7115    71254                                 gamer     4.007557\n",
       "0           1                             toy story     4.000000\n",
       "53         60           indian in the cupboard, the     4.000000\n",
       "82         93                   vampire in brooklyn     4.000000\n",
       "499       579                           escort, the     3.999252\n",
       "6014    39292            good night, and good luck.     3.954468\n",
       "8468   113278             batman: assault on arkham     3.941009\n",
       "8746   128594                        boy meets girl     3.929628\n",
       "3865     5442                      v. i. warshawski     3.927033\n",
       "2705     3634                     seven days in may     3.922425\n",
       "9220   153386                     long live ghosts!     3.916527\n",
       "4457     6588    and now... ladies and gentlemen...     3.908459\n",
       "8835   132888  comedy central roast of james franco     3.882490\n",
       "5016     7820                    virgin spring, the     3.880780\n",
       "5563    26791                       shining through     3.861796\n",
       "1395     1914                         smoke signals     3.839327\n",
       "5346     8934                           bebe's kids     3.834800"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top-N-movies\n",
    "prediction(X,my_ratings,moviesdataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-tragedy",
   "metadata": {},
   "source": [
    "# Save learned Features for movies\n",
    "Nextly I will start flask web application development and for that I will use the feature vectors for all movies learned using a collaborative filtering algorithm to that end I'm going to save them and load them in flask web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "relevant-explorer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Movies_Datase.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    " \n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(X, 'Movies_Learned_Features.pkl')\n",
    "joblib.dump(moviesdataset, 'Movies_Datase.pkl')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-burlington",
   "metadata": {},
   "source": [
    "# Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-mortgage",
   "metadata": {},
   "source": [
    "The next step is flask web application development and deployment. Flask web application development code is available in the server directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
